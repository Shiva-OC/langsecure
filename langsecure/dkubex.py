from typing import List, Optional, Dict
from nemoguardrails.llm.providers import register_llm_provider
from nemoguardrails.llm.providers.nemollm import NeMoLLM
import logging
from langchain.callbacks.manager import (
    AsyncCallbackManagerForLLMRun,
    CallbackManagerForLLMRun
)
import httpx
from httpx import HTTPStatusError
log = logging.getLogger(__name__)


class DKubeXLLM(NeMoLLM):
    """DKubeX LLM engine implementation."""

    base_url: str
    api_key: str
    model: str

    def _get_request_url(self) -> str:
        return self.base_url + "/completions"
    
    def _get_request_json(self, prompt: str, stop: Optional[List[str]] = None) -> Dict:
        if stop is None:
            stop = []

        return {
            "model": self.model,
            "prompt": prompt,
            "stop": stop,
            "temperature": self.temperature,
        }

    async def _acall(
        self,
        prompt: str,
        stop: Optional[List[str]] = None,
        run_manager: Optional[AsyncCallbackManagerForLLMRun] = None,
        **kwargs,
    ) -> str:
        """Call out to DKubeX completion endpoint.

        Args:
            prompt: The prompt to pass into the model.
            stop: Optional list of stop words to use when generating.

        Returns:
            The string generated by the model.
        """
        stop = self.stop if stop is None else stop
        if self.streaming:
            completion = ""
            async for chunk in self._astream(
                prompt=prompt, stop=stop, run_manager=run_manager, **kwargs
            ):
                completion += chunk.text
            return completion

        async with httpx.AsyncClient(timeout=self._get_timeout()) as client:
            response = await client.post(
                url=self._get_request_url(),
                headers=self._get_request_headers(),
                json=self._get_request_json(prompt, stop),
            )

        if response.status_code == 401:
            # Gives a more helpful error message for the forbidden status code 401
            # All other status codes except 200 and 401 are handled by response.raise_for_status()
            message = "Unauthorized request to the LLM API. Please set a valid API key."
            raise HTTPStatusError(
                message=message, request=response._request, response=response
            )

        response.raise_for_status()

        return response.json()["choices"][0]["text"]
    
    def _call(
        self,
        prompt: str,
        stop: Optional[List[str]] = None,
        run_manager: Optional[CallbackManagerForLLMRun] = None,
        **kwargs,
    ) -> str:
        stop = self.stop if stop is None else stop
        if self.streaming:
            completion = ""
            for chunk in self._stream(
                prompt=prompt, stop=stop, run_manager=run_manager, **kwargs
            ):
                completion += chunk.text
            return completion

        with httpx.Client(timeout=self._get_timeout()) as client:
            response = client.post(
                url=self._get_request_url(),
                headers=self._get_request_headers(),
                json=self._get_request_json(prompt, stop),
            )

        if response.status_code == 401:
            # Gives a more helpful error message for the forbidden status code 401
            # All other status codes except 200 and 401 are handled by response.raise_for_status()
            message = "Unauthorized request to the LLM API. Please set a valid API key using the NGC_API_KEY environment variable."
            raise HTTPStatusError(
                message=message, request=response._request, response=response
            )

        response.raise_for_status()

        return response.json()["choices"][0]["text"]
    @property
    def _llm_type(self) -> str:
        return "dkubex"
 
    @property
    def _identifying_params(self) -> dict:
        return {"base_url": self.base_url, "token": self.api_key}



# Register the LLM provider
register_llm_provider("dkubex", DKubeXLLM)

